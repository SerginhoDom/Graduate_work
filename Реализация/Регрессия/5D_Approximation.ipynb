{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from kan import KAN\n",
    "import uuid\n",
    "\n",
    "# Установка сида для воспроизводимости\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Проверка доступности CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_function(X):\n",
    "    x1, x2, x3, x4, x5 = X[:, 0], X[:, 1], X[:, 2], X[:, 3], X[:, 4]\n",
    "    part1 = np.sin(np.exp(x1 + x2))\n",
    "    part2 = np.log(1 + x3**2 + np.cos(x4))\n",
    "    part3 = - np.sqrt(np.abs(x5))\n",
    "    return part1 + part2 + part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "N_test = 1000\n",
    "\n",
    "x_train = np.random.uniform(-2, 2, size=(N_train, 5))\n",
    "y_train = true_function(x_train).reshape(-1, 1)\n",
    "x_test = np.random.uniform(-2, 2, size=(N_test, 5))\n",
    "y_test = true_function(x_test).reshape(-1, 1)\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            if i < len(layers) - 2:\n",
    "                self.layers.append(nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(model, x, y, epochs=1000, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(loss.item())\n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_configs = [\n",
    "    {\"layers\": [5, 50, 50, 1], \"epochs\": 2000, \"lr\": 0.001, \"name\": \"MLP Medium\"},\n",
    "    {\"layers\": [5, 100, 100, 100, 1], \"epochs\": 3000, \"lr\": 0.0005, \"name\": \"MLP Deep\"},\n",
    "]\n",
    "\n",
    "mlp_models = []\n",
    "mlp_predictions = []\n",
    "mlp_mse = []\n",
    "mlp_loss_histories = []\n",
    "\n",
    "for config in mlp_configs:\n",
    "    mlp_model = MLP(config[\"layers\"])\n",
    "    mlp_model, loss_history = train_mlp(mlp_model, x_train_tensor, y_train_tensor, config[\"epochs\"], config[\"lr\"])\n",
    "    mlp_models.append(mlp_model)\n",
    "    mlp_loss_histories.append(loss_history)\n",
    "    with torch.no_grad():\n",
    "        y_pred = mlp_model(x_test_tensor).cpu().numpy()\n",
    "        mlp_predictions.append(y_pred)\n",
    "        mse = np.mean((y_pred - y_test)**2)\n",
    "        mlp_mse.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_configs = [\n",
    "    {\"width\": [5, 5, 1], \"grid\": 15, \"k\": 3, \"name\": \"KAN Small\"},\n",
    "    {\"width\": [5, 10, 1], \"grid\": 15, \"k\": 3, \"name\": \"KAN Medium\"},\n",
    "]\n",
    "\n",
    "kan_models = []\n",
    "kan_predictions = []\n",
    "kan_mse = []\n",
    "kan_loss_histories = []\n",
    "\n",
    "for config in kan_configs:\n",
    "    kan_model = KAN(width=config[\"width\"], grid=config[\"grid\"], k=config[\"k\"], device=device)\n",
    "    dataset = {\n",
    "        \"train_input\": x_train_tensor,\n",
    "        \"train_label\": y_train_tensor,\n",
    "        \"test_input\": x_test_tensor,\n",
    "        \"test_label\": y_test_tensor\n",
    "    }\n",
    "    results = kan_model.fit(dataset, opt=\"LBFGS\", steps=300, lamb=0.01)\n",
    "    kan_model(dataset['train_input'])\n",
    "    kan_models.append(kan_model)\n",
    "    y_pred = kan_model(x_test_tensor).detach().cpu().numpy()\n",
    "    kan_predictions.append(y_pred)\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    kan_mse.append(mse)\n",
    "    kan_loss_histories.append(results['train_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, loss_history in enumerate(mlp_loss_histories):\n",
    "    plt.plot(range(len(loss_history)), loss_history, label=mlp_configs[i]['name'])\n",
    "plt.title(\"MLP Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, loss_history in enumerate(kan_loss_histories):\n",
    "    plt.plot(range(len(loss_history)), loss_history, label=kan_configs[i]['name'])\n",
    "plt.title(\"KAN Loss Curves\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Train MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mlp_kan_compositional_5d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Для MLP рисуем по эпохам\n",
    "for i, loss_history in enumerate(mlp_loss_histories):\n",
    "    plt.plot(range(len(loss_history)), loss_history, label=mlp_configs[i]['name'] + \" (MLP)\")\n",
    "\n",
    "# Для KAN рисуем по шагам\n",
    "for i, loss_history in enumerate(kan_loss_histories):\n",
    "    plt.plot(range(len(loss_history)), loss_history, label=kan_configs[i]['name'] + \" (KAN)\")\n",
    "\n",
    "plt.title(\"Сравнение обучения MLP и KAN (Train MSE)\")\n",
    "plt.xlabel(\"Эпоха / Шаг\")\n",
    "plt.ylabel(\"Ошибка (MSE)\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mlp_kan_comparison_loss_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"auto\" # \"manual\"\n",
    "\n",
    "if mode == \"manual\":\n",
    "    # manual mode\n",
    "    kan_model.fix_symbolic(0,0,0,'sin');\n",
    "    kan_model.fix_symbolic(0,1,0,'x^2');\n",
    "    kan_model.fix_symbolic(1,0,0,'exp');\n",
    "elif mode == \"auto\":\n",
    "    # automatic mode\n",
    "    lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs', 'cos']\n",
    "    kan_model.auto_symbolic(lib=lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_model.symbolic_formula()[0][0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
